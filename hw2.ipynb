{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GwUGWNG-K86L"
   },
   "source": [
    "## Homework 2\n",
    "*For any questions or concerns please email your instructor at `smanna@scu.edu`*\n",
    "### Due - 05/04/2020 - 11:59p - 20 points\n",
    "\n",
    "**Name:** Jeffrey Lin\n",
    "\n",
    "**Email:**  jlin7@scu.edu\n",
    "\n",
    "**Objectives:** The main aim of this homework is to make you conversant with `Perceptron Training Rule` and use it as a simple binary classifier.\n",
    "\n",
    "**Submission Instructions:** \n",
    "* Please download `hw2.ipynb`, `train.csv`, and `test.csv` files and insert cells in the `hw2.ipynb` to complete your homework and submit the same file to Camino under `Homework` $\\rightarrow$ `hw2`.\n",
    "* Please make sure you type your `Name` and `Email` on top of your submission file in the placeholder above. \n",
    "\n",
    "**Honor Code:** You are expected to complete the homework on your own. Solutions might exist elsewhere, but you are not allowed to copy them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DPQE0TdlK86M"
   },
   "source": [
    "### Problem Statement\n",
    "You are given a dataset of different `Iris` flower species. The original [dataset](https://archive.ics.uci.edu/ml/datasets/iris) has detailed description of all the characteristics of the flowers. Please feel free to visit the original page to know more about the dataset. Your task is to develop a simple linear binary classifier using `perceptron training rule` and `delta rule using batch gradient descent` to categorize the flowers based on their species.\n",
    "\n",
    "**Adaptation**: To make the dataset work for this *homework*, we have modified the original dataset. You can use `train.csv` to train the parameters of your model and then use `test.csv` to test your model on some unknown dataset.\n",
    "\n",
    "**Evaluation**: We have set aside another dataset similar to `test.csv` which will not be disclosed to you. We will use that dataset to evaluate your algorithm. This is just to make sure that you do not have any hard-coded parameters in your code.\n",
    "\n",
    "**Note**: Please make sure you have proper comments and explanation/justification of the steps you have coded. Please feel to add extra cells to complete all the `TODO` stubs. You are allowed to create your own utility functions to support your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DcJ3CEhfK86N"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define headers since the dataset does not have any headers\n",
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-0NZTj_2K86T"
   },
   "outputs": [],
   "source": [
    "# Import csv file into pandas dataframe'\n",
    "# TODO\n",
    "fnametrain ='train.csv'\n",
    "traindata = pd.read_csv(fnametrain, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rKWSM8KHK86W"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.820513</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.782051</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.628205</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.910256</td>\n",
       "      <td>0.397436</td>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.217949</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0      0.794872     0.410256      0.756410     0.307692        0\n",
       "1      0.551282     0.371795      0.153846     0.012821        1\n",
       "2      0.628205     0.243590      0.435897     0.115385        1\n",
       "3      0.628205     0.410256      0.166667     0.012821        1\n",
       "4      0.628205     0.397436      0.141026     0.012821        1\n",
       "5      0.820513     0.371795      0.653846     0.243590        0\n",
       "6      0.782051     0.358974      0.538462     0.153846        1\n",
       "7      0.628205     0.423077      0.192308     0.038462        1\n",
       "8      0.730769     0.333333      0.512821     0.115385        1\n",
       "9      0.910256     0.397436      0.756410     0.217949        0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 10 rows of the training data\n",
    "# TODO\n",
    "traindata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "53lwjrLbK86Z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "560"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of training data\n",
    "# TODO\n",
    "traindata.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RkVGYpgjK86c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal_length    float64\n",
       "sepal_width     float64\n",
       "petal_length    float64\n",
       "petal_width     float64\n",
       "species           int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the data types for each columns of your dataset\n",
    "# TODO\n",
    "traindata.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-LrNwUkK86e"
   },
   "outputs": [],
   "source": [
    "# Separating features and store in X_train\n",
    "# TODO\n",
    "X_train = traindata[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pp4-lg8vK86l"
   },
   "outputs": [],
   "source": [
    "# Assigning y_train (species) from the dataset\n",
    "# TODO\n",
    "y_train = traindata['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qc71WGDLK86o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the number of y values in the training dataset\n",
    "# TODO\n",
    "y_train.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7M74uReTK86r"
   },
   "source": [
    "**Activation functions**: You have to implement two different activation functions, `sgn` and `sigmoid`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ws6PzRfhK86r"
   },
   "outputs": [],
   "source": [
    "# implementation of sign activation\n",
    "#def sgn(x): # if x > 0 then return 1, and 0 otherwise\n",
    "# TODO\n",
    "def sgn(x):\n",
    "    if x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9RS1051DK86u"
   },
   "outputs": [],
   "source": [
    "# implementation of sigmoid activation\n",
    "#def sigmoid(x):\n",
    "# TODO\n",
    "def sigmoid(x):\n",
    "    return 1.0 / (1.0 + np.exp(-x)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J2Twe_08K86z"
   },
   "source": [
    "**Training Rules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m_gmelsbK860"
   },
   "outputs": [],
   "source": [
    "# implementation of perceptron training algorithm\n",
    "def PTR(X, y, num_iter, learning_rate, activation_func):\n",
    "    N, d = np.shape(X) # number of samples and number of features\n",
    "    W = np.zeros(NUM_FEATURES, np.float32) # 2x1, weight\n",
    "    b = np.zeros(1, np.float32) # 1x1\n",
    "    for k in range(num_iter):\n",
    "       for j in range(N): #N = Number of samples\n",
    "         yHat_j = X.iloc[j, :].dot(W) + b # 1x2, 2x1\n",
    "         yHat_j = activation_func(yHat_j) # activation function\n",
    "         \n",
    "         err = y[j] - yHat_j # error term\n",
    "         deltaW = err * X.iloc[j, :]\n",
    "         \n",
    "         deltaB = err\n",
    "         W = W + learning_rate * deltaW # if err = y - yHat, then W = W + lRate * deltW\n",
    "         b = b + learning_rate * deltaB\n",
    "    return W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EELH9hKXK862"
   },
   "outputs": [],
   "source": [
    "# implementation of delta rule using batch gradient decent\n",
    "def BGD(X, y, num_iter, learning_rate):\n",
    "#     TODO\n",
    "#    return W, b, cost \n",
    "    N, d = np.shape(X_train) # number of samples and number of features\n",
    "\n",
    "    cost = np.zeros(num_iter) \n",
    "    W = np.zeros((NUM_FEATURES), np.float32) # 3x1, weight\n",
    "    b = 0 # 1x1\n",
    "\n",
    "    for k in range(num_iter):\n",
    "        yHat = np.dot(X, W) + b\n",
    "        err = y - yHat\n",
    "        W += learning_rate * X.T.dot(err)\n",
    "        b += learning_rate * err.sum() # err.sum() == np.ones((1, N)).dot(err)[0][0]\n",
    "        cost[k] = (err**2).sum() / 2.0\n",
    "    return W, b, cost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1MK_PuX0K864"
   },
   "outputs": [],
   "source": [
    "# Learning parameters using Batch Gradient Descent for training\n",
    "W_bgd, b_bgd, cost_bgd = BGD(X_train, y_train, 2500, 0.001) \n",
    "# try out with different num_iterations, and learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B22RvGMMK866"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot cost (as computed in batch gradient descent)\n",
    "# with `No. of iterations` in x-axis, and `Cost` in y-axis\n",
    "# TODO\n",
    "plt.plot(cost_bgd)\n",
    "plt.xlabel(\"# iterations\")\n",
    "plt.ylabel(\"cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_djkrL9IK868"
   },
   "outputs": [],
   "source": [
    "# Learning parameters using Perceptron training rule function\n",
    "W_ptr, b_ptr = PTR(X_train, y_train, 1000, 0.01, sigmoid)\n",
    "# try out with different num_iterations, and learning_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OwmDetM1K86-"
   },
   "source": [
    "**Prediction Begins**: I have provided you with two utility functions `Identity` and `predict` which you will need to use it on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GIqaUbMpK86_"
   },
   "outputs": [],
   "source": [
    "# An activation, that does nothing. Used to disable activation_function.\n",
    "def Identity(x):\n",
    "    return x\n",
    "\n",
    "# The neural network thinks.\n",
    "def predict(x_test, weights, bias, activation_func=Identity):\n",
    "    return activation_func(np.dot(x_test, weights) + bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tEg3XYhDK87B"
   },
   "outputs": [],
   "source": [
    "# Read test data into pandas dataframe\n",
    "# TODO\n",
    "fnametest = 'test.csv'\n",
    "testdata = pd.read_csv(fnametest, names = col_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "js2riI8ZK87D",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.602564</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.307692</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.179487</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.282051</td>\n",
       "      <td>0.551282</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.974359</td>\n",
       "      <td>0.474359</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.717949</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>0.525641</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.756410</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.641026</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.320513</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.141026</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.858974</td>\n",
       "      <td>0.371795</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.256410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.294872</td>\n",
       "      <td>0.410256</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.705128</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.243590</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width  species\n",
       "0      0.858974     0.346154      0.602564     0.166667        1\n",
       "1      0.794872     0.307692      0.615385     0.179487        1\n",
       "2      0.794872     0.282051      0.551282     0.153846        1\n",
       "3      0.974359     0.474359      0.846154     0.269231        0\n",
       "4      0.717949     0.358974      0.525641     0.153846        1\n",
       "5      0.756410     0.333333      0.641026     0.192308        1\n",
       "6      0.730769     0.320513      0.500000     0.141026        1\n",
       "7      0.858974     0.371795      0.692308     0.256410        0\n",
       "8      0.615385     0.294872      0.410256     0.115385        1\n",
       "9      0.705128     0.346154      0.615385     0.243590        0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print first 10 rows of the test data\n",
    "# TODO\n",
    "testdata.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0lJOlFIHK87K"
   },
   "outputs": [],
   "source": [
    "# features of test\n",
    "# Separating feature and output columns from the dataset and store in X_test\n",
    "# TODO\n",
    "X_test = testdata[[\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "33DL9yTUK87M"
   },
   "outputs": [],
   "source": [
    "# store actual output (target) into y_test\n",
    "# TODO\n",
    "y_test = testdata['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1Xjy9hzFK87O"
   },
   "outputs": [],
   "source": [
    "# Compute predictions with X_test\n",
    "y_pred_ptr = predict(X_test, W_ptr, b_ptr, sigmoid) # feel free to explore results using `sgn` activation function\n",
    "y_pred_bgd = predict(X_test, W_bgd, b_bgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.58694515 0.4808575  0.71698518 0.03355405 0.80956414 0.38230429\n",
      " 0.85801345 0.17600084 0.95613271 0.3624916  0.99931483 0.83865706\n",
      " 0.88376281 0.11654153 0.7057043  0.08417539 0.44118397 0.99946448\n",
      " 0.79687306]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49895535 0.47187252 0.58636082 0.06698166 0.57163822 0.40989641\n",
      " 0.63387366 0.27738235 0.75646942 0.36266007 1.10316567 0.57897421\n",
      " 0.66436456 0.20931521 0.49807417 0.2445012  0.39558643 1.0941766\n",
      " 0.57924812]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred_bgd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yz6Zq2qdK87Q"
   },
   "source": [
    "**Evaluation Metrics** We will evaluate our predictions using `Root Mean Squared Error`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdPRwO4dK87Q"
   },
   "outputs": [],
   "source": [
    "# Evaluate using RMSE\n",
    "def RMSE(target, output):\n",
    "    return math.sqrt(((target - output) ** 2).mean(axis=None))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePvRkJujK87Z"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the rmse is: ', 0.28156946527540455)\n"
     ]
    }
   ],
   "source": [
    "rmse_ptr = RMSE(y_test, y_pred_ptr)\n",
    "print('the rmse is: ', rmse_ptr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8qMqjF3ZK87c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the rmse is: ', 0.3725836923415349)\n"
     ]
    }
   ],
   "source": [
    "rmse_bgd = RMSE(y_test, y_pred_bgd)\n",
    "print('the rmse is: ', rmse_bgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
