{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yWlD84BSIAo9"
   },
   "source": [
    "## Homework 3\n",
    "*For any questions or concerns please email your instructor at `smanna@scu.edu`*\n",
    "### Due - 05/15/2020 - 11:59p - 100 points\n",
    "\n",
    "**Name:** `<Jeffrey Lin>`\n",
    "\n",
    "**Email** `<jlin7@scu.edu>`\n",
    "\n",
    "**Objectives:** \n",
    "* Implement and understand multi-class classifier using MLP\n",
    "* Familiarity with `Keras`\n",
    "\n",
    "**Submission Instructions:** \n",
    "* Please download `hw3.ipynb`, `train_nn.csv`, and `test_nn.csv` files and insert cells in the `hw3.ipynb` to complete your homework and submit the same file to Camino under `Homework` $\\rightarrow$ `hw3`.\n",
    "* Please make sure you type your `Name` and `Email` on top of your submission file in the placeholder above. \n",
    "\n",
    "**Honor Code:** You are expected to complete the homework on your own. Solutions might exist elsewhere, but you are not allowed to copy them. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W0mtunijIAo-"
   },
   "source": [
    "### Problem Statement\n",
    "You are given a dataset of different `Iris` flower species. The original [dataset](https://archive.ics.uci.edu/ml/datasets/iris) has detailed description of all the characteristics of the flowers. Please feel free to visit the original page to know more about the dataset. Your task is to develop a Neural Network based multi-class classifier using `Keras` to categorize the flowers based on their species. \n",
    "\n",
    "**Guide**: Feel free to use `week6-keras-diabetes.ipynb` as a sample to kick-start your implentation. If you simply try to copy and paste the code into your homework, trust me, it won't work!!! \n",
    "\n",
    "Here are few things you can try:\n",
    "* *One hot encoding*: There are three `species` of iris flower in your dataset. This time, you have to classify your data into `three` different categories. For that you need to compute `one hot encoding`.\n",
    "* *Activation functions*: There are different activation functions used in Neural Network (NN). Your task is to research different activation functions such as SoftMax, ReLu, and Sigmoid, and learn which ones are suitable for which layers of your neural network. Based on that, design your NN architecture and check the performance by computing `accuracy`.\n",
    "* *Number of hidden layers*: Instead on using one hidden layer, you can try two and check out your results and check the performance by computing `accuracy`.\n",
    "* *Loss functions*: Keras comes with different  `loss` functions. Your task is to review them and pick any two to report your findings.\n",
    "\n",
    "**Adaptation**: We have provided you with the original dataset splitting it into two, one for training and the other for testing. You can use `train_nn.csv` to train the parameters of your model and then use `test_nn.csv` to test your model.\n",
    "\n",
    "**Note**: Please make sure you have proper comments and explanation/justification of the steps you have coded. Please feel to add extra cells to complete all the `TODO` stubs. You are allowed to create your own utility functions to support your code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5SAF0GwoIAo-"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "# TODO - feel free to add more as you need!\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jqZalYReIApB"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "1           4.9          3.1           1.5          0.1  Iris-setosa\n",
       "2           4.4          3.0           1.3          0.2  Iris-setosa\n",
       "3           5.1          3.4           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.5           1.3          0.3  Iris-setosa\n",
       "5           4.5          2.3           1.3          0.3  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Loading the train Iris dataset'\n",
    "# Define headers since the dataset does not have any headers\n",
    "col_names = [\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\", \"species\"]\n",
    "# reading the training data into the data frame\n",
    "train_df = pd.read_csv('train_NN.csv', header=None, names=col_names)\n",
    "# reading the test data into the data frame\n",
    "test_df = pd.read_csv('test_NN.csv', header=None, names=col_names)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    Iris-setosa\n",
      "2    Iris-setosa\n",
      "3    Iris-setosa\n",
      "4    Iris-setosa\n",
      "5    Iris-setosa\n",
      "Name: species, dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width\n",
       "1           5.1          3.5           1.4          0.2\n",
       "2           4.9          3.0           1.4          0.2\n",
       "3           4.7          3.2           1.3          0.2\n",
       "4           4.6          3.1           1.5          0.2\n",
       "5           5.0          3.6           1.4          0.2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove and missing Values in the dataset\n",
    "train_df_label = train_df['species']\n",
    "train_df_features = train_df.drop('species', 1)\n",
    "train_df_features.replace('?', -99999, inplace=True)\n",
    "\n",
    "test_df_label = test_df['species']\n",
    "test_df_features = test_df.drop('species', 1)\n",
    "test_df.replace('?', -99999, inplace=True)\n",
    "\n",
    "print(train_df_label.head())\n",
    "train_df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cm07B6irIApE"
   },
   "outputs": [],
   "source": [
    "'Perform One Hot Encoding for the classifier to work'\n",
    "# TODO\n",
    "trainlabel = []\n",
    "for lab in train_df_label:\n",
    "    if lab == 'Iris-setosa':\n",
    "        trainlabel.append([1, 0, 0])  # class 2\n",
    "    elif lab == 'Iris-versicolor':\n",
    "        trainlabel.append([0, 1, 0])  # class 1\n",
    "    elif lab == 'Iris-virginica':\n",
    "        trainlabel.append([0, 0, 1])  # class 0\n",
    "\n",
    "testlabel = []\n",
    "for lab in test_df_features:\n",
    "    if lab == 'Iris-setosa':\n",
    "        testlabel.append([1, 0, 0])  # class 2\n",
    "    elif lab == 'Iris-versicolor':\n",
    "        testlabel.append([0, 1, 0])  # class 1\n",
    "    elif lab == 'Iris-virginica':\n",
    "        testlabel.append([0, 0, 1])  # class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJE3Kb7gIApG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((112, 4), (112, 3))\n",
      "((112, 4), (112, 3))\n"
     ]
    }
   ],
   "source": [
    "'Assigning features and output columns and converting them into numpy arrays'\n",
    "# this is upto you.\n",
    "# you can do it in your way\n",
    "# TODO (optional)\n",
    "train_data = np.array(train_df_features)\n",
    "train_label = np.array(trainlabel)\n",
    "print(train_data.shape,train_label.shape)\n",
    "\n",
    "test_data = np.array(test_df_features)\n",
    "test_label = np.array(testlabel)\n",
    "print(train_data.shape,train_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LR92voUGIApL"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112, 4)\n",
      "(38, 4)\n"
     ]
    }
   ],
   "source": [
    "# Printing the dimensions of your train, and test data\n",
    "# TODO\n",
    "#x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.2, random_state=42)\n",
    "x_train = train_data\n",
    "y_train = train_label\n",
    "print(x_train.shape)\n",
    "\n",
    "x_test = test_data\n",
    "y_test = testlabel\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8Cz2IQCIApT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 112 samples, validate on 112 samples\n",
      "Epoch 1/1000\n",
      "112/112 [==============================] - 0s 1ms/step - loss: 0.2353 - accuracy: 0.2589 - val_loss: 0.2229 - val_accuracy: 0.3304\n",
      "Epoch 2/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.2228 - accuracy: 0.3304 - val_loss: 0.2188 - val_accuracy: 0.3393\n",
      "Epoch 3/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.2191 - accuracy: 0.4821 - val_loss: 0.2202 - val_accuracy: 0.3304\n",
      "Epoch 4/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.2195 - accuracy: 0.3304 - val_loss: 0.2133 - val_accuracy: 0.3304\n",
      "Epoch 5/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.2111 - accuracy: 0.3750 - val_loss: 0.2049 - val_accuracy: 0.6696\n",
      "Epoch 6/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.2040 - accuracy: 0.7054 - val_loss: 0.2053 - val_accuracy: 0.4821\n",
      "Epoch 7/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.2065 - accuracy: 0.4018 - val_loss: 0.2034 - val_accuracy: 0.4286\n",
      "Epoch 8/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.2025 - accuracy: 0.4554 - val_loss: 0.1961 - val_accuracy: 0.8839\n",
      "Epoch 9/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.1943 - accuracy: 0.8393 - val_loss: 0.1921 - val_accuracy: 0.5893\n",
      "Epoch 10/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.1924 - accuracy: 0.5268 - val_loss: 0.1901 - val_accuracy: 0.5804\n",
      "Epoch 11/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.1893 - accuracy: 0.6161 - val_loss: 0.1844 - val_accuracy: 0.6696\n",
      "Epoch 12/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.1842 - accuracy: 0.6696 - val_loss: 0.1817 - val_accuracy: 0.6696\n",
      "Epoch 13/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.1808 - accuracy: 0.6696 - val_loss: 0.1759 - val_accuracy: 0.6696\n",
      "Epoch 14/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.1746 - accuracy: 0.6696 - val_loss: 0.1718 - val_accuracy: 0.7232\n",
      "Epoch 15/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.1712 - accuracy: 0.8036 - val_loss: 0.1690 - val_accuracy: 0.8393\n",
      "Epoch 16/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.1683 - accuracy: 0.8304 - val_loss: 0.1638 - val_accuracy: 0.7054\n",
      "Epoch 17/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.1624 - accuracy: 0.6875 - val_loss: 0.1581 - val_accuracy: 0.6696\n",
      "Epoch 18/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.1596 - accuracy: 0.6696 - val_loss: 0.1555 - val_accuracy: 0.6696\n",
      "Epoch 19/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.1546 - accuracy: 0.6696 - val_loss: 0.1501 - val_accuracy: 0.6696\n",
      "Epoch 20/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.1501 - accuracy: 0.6696 - val_loss: 0.1459 - val_accuracy: 0.6696\n",
      "Epoch 21/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.1452 - accuracy: 0.6696 - val_loss: 0.1414 - val_accuracy: 0.6696\n",
      "Epoch 22/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.1408 - accuracy: 0.6696 - val_loss: 0.1380 - val_accuracy: 0.7054\n",
      "Epoch 23/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.1372 - accuracy: 0.7232 - val_loss: 0.1342 - val_accuracy: 0.7768\n",
      "Epoch 24/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.1336 - accuracy: 0.7768 - val_loss: 0.1303 - val_accuracy: 0.7679\n",
      "Epoch 25/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.1301 - accuracy: 0.7679 - val_loss: 0.1267 - val_accuracy: 0.6964\n",
      "Epoch 26/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.1260 - accuracy: 0.7143 - val_loss: 0.1237 - val_accuracy: 0.6786\n",
      "Epoch 27/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.1233 - accuracy: 0.6875 - val_loss: 0.1208 - val_accuracy: 0.6786\n",
      "Epoch 28/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.1202 - accuracy: 0.6786 - val_loss: 0.1175 - val_accuracy: 0.7143\n",
      "Epoch 29/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.1169 - accuracy: 0.7411 - val_loss: 0.1145 - val_accuracy: 0.7857\n",
      "Epoch 30/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.1145 - accuracy: 0.8214 - val_loss: 0.1123 - val_accuracy: 0.9375\n",
      "Epoch 31/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.1123 - accuracy: 0.9464 - val_loss: 0.1091 - val_accuracy: 0.8750\n",
      "Epoch 32/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.1082 - accuracy: 0.8571 - val_loss: 0.1074 - val_accuracy: 0.7679\n",
      "Epoch 33/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.1073 - accuracy: 0.7321 - val_loss: 0.1059 - val_accuracy: 0.7232\n",
      "Epoch 34/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.1052 - accuracy: 0.7232 - val_loss: 0.1021 - val_accuracy: 0.8304\n",
      "Epoch 35/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.1015 - accuracy: 0.8661 - val_loss: 0.1004 - val_accuracy: 0.9732\n",
      "Epoch 36/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.1005 - accuracy: 0.9464 - val_loss: 0.0985 - val_accuracy: 0.9375\n",
      "Epoch 37/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0978 - accuracy: 0.9554 - val_loss: 0.0955 - val_accuracy: 0.8929\n",
      "Epoch 38/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0955 - accuracy: 0.8661 - val_loss: 0.0942 - val_accuracy: 0.8214\n",
      "Epoch 39/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0945 - accuracy: 0.8036 - val_loss: 0.0915 - val_accuracy: 0.8929\n",
      "Epoch 40/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0932 - accuracy: 0.9018 - val_loss: 0.0910 - val_accuracy: 0.9375\n",
      "Epoch 41/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0907 - accuracy: 0.9375 - val_loss: 0.0877 - val_accuracy: 0.9554\n",
      "Epoch 42/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0889 - accuracy: 0.9286 - val_loss: 0.0875 - val_accuracy: 0.8304\n",
      "Epoch 43/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0870 - accuracy: 0.8482 - val_loss: 0.0845 - val_accuracy: 0.8929\n",
      "Epoch 44/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0844 - accuracy: 0.9107 - val_loss: 0.0827 - val_accuracy: 0.9554\n",
      "Epoch 45/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0824 - accuracy: 0.9554 - val_loss: 0.0810 - val_accuracy: 0.9554\n",
      "Epoch 46/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0808 - accuracy: 0.9554 - val_loss: 0.0790 - val_accuracy: 0.9643\n",
      "Epoch 47/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0785 - accuracy: 0.9643 - val_loss: 0.0779 - val_accuracy: 0.9196\n",
      "Epoch 48/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0800 - accuracy: 0.8839 - val_loss: 0.0766 - val_accuracy: 0.9107\n",
      "Epoch 49/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0761 - accuracy: 0.9375 - val_loss: 0.0752 - val_accuracy: 0.9375\n",
      "Epoch 50/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0748 - accuracy: 0.9375 - val_loss: 0.0742 - val_accuracy: 0.9375\n",
      "Epoch 51/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0740 - accuracy: 0.9375 - val_loss: 0.0713 - val_accuracy: 0.9732\n",
      "Epoch 52/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0727 - accuracy: 0.9375 - val_loss: 0.0713 - val_accuracy: 0.9107\n",
      "Epoch 53/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0708 - accuracy: 0.9196 - val_loss: 0.0686 - val_accuracy: 0.9554\n",
      "Epoch 54/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0692 - accuracy: 0.9554 - val_loss: 0.0681 - val_accuracy: 0.9375\n",
      "Epoch 55/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0683 - accuracy: 0.9375 - val_loss: 0.0659 - val_accuracy: 0.9554\n",
      "Epoch 56/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0652 - accuracy: 0.9554 - val_loss: 0.0660 - val_accuracy: 0.9286\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0659 - accuracy: 0.9286 - val_loss: 0.0648 - val_accuracy: 0.9286\n",
      "Epoch 58/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0643 - accuracy: 0.9286 - val_loss: 0.0620 - val_accuracy: 0.9643\n",
      "Epoch 59/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0625 - accuracy: 0.9643 - val_loss: 0.0615 - val_accuracy: 0.9554\n",
      "Epoch 60/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0614 - accuracy: 0.9464 - val_loss: 0.0596 - val_accuracy: 0.9732\n",
      "Epoch 61/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0594 - accuracy: 0.9643 - val_loss: 0.0586 - val_accuracy: 0.9643\n",
      "Epoch 62/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0586 - accuracy: 0.9643 - val_loss: 0.0575 - val_accuracy: 0.9643\n",
      "Epoch 63/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0574 - accuracy: 0.9643 - val_loss: 0.0563 - val_accuracy: 0.9643\n",
      "Epoch 64/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0563 - accuracy: 0.9643 - val_loss: 0.0552 - val_accuracy: 0.9643\n",
      "Epoch 65/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0552 - accuracy: 0.9643 - val_loss: 0.0542 - val_accuracy: 0.9643\n",
      "Epoch 66/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0541 - accuracy: 0.9643 - val_loss: 0.0532 - val_accuracy: 0.9643\n",
      "Epoch 67/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0532 - accuracy: 0.9643 - val_loss: 0.0522 - val_accuracy: 0.9643\n",
      "Epoch 68/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0521 - accuracy: 0.9554 - val_loss: 0.0518 - val_accuracy: 0.9554\n",
      "Epoch 69/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0518 - accuracy: 0.9464 - val_loss: 0.0502 - val_accuracy: 0.9554\n",
      "Epoch 70/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0501 - accuracy: 0.9554 - val_loss: 0.0493 - val_accuracy: 0.9643\n",
      "Epoch 71/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0492 - accuracy: 0.9643 - val_loss: 0.0484 - val_accuracy: 0.9643\n",
      "Epoch 72/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0484 - accuracy: 0.9643 - val_loss: 0.0474 - val_accuracy: 0.9732\n",
      "Epoch 73/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0472 - accuracy: 0.9643 - val_loss: 0.0469 - val_accuracy: 0.9464\n",
      "Epoch 74/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0476 - accuracy: 0.9464 - val_loss: 0.0458 - val_accuracy: 0.9554\n",
      "Epoch 75/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0463 - accuracy: 0.9554 - val_loss: 0.0463 - val_accuracy: 0.9554\n",
      "Epoch 76/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0460 - accuracy: 0.9554 - val_loss: 0.0444 - val_accuracy: 0.9643\n",
      "Epoch 77/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0441 - accuracy: 0.9643 - val_loss: 0.0439 - val_accuracy: 0.9554\n",
      "Epoch 78/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0438 - accuracy: 0.9554 - val_loss: 0.0433 - val_accuracy: 0.9554\n",
      "Epoch 79/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0430 - accuracy: 0.9554 - val_loss: 0.0419 - val_accuracy: 0.9732\n",
      "Epoch 80/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0423 - accuracy: 0.9732 - val_loss: 0.0416 - val_accuracy: 0.9643\n",
      "Epoch 81/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0417 - accuracy: 0.9643 - val_loss: 0.0406 - val_accuracy: 0.9732\n",
      "Epoch 82/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0408 - accuracy: 0.9643 - val_loss: 0.0412 - val_accuracy: 0.9643\n",
      "Epoch 83/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0410 - accuracy: 0.9643 - val_loss: 0.0394 - val_accuracy: 0.9554\n",
      "Epoch 84/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0390 - accuracy: 0.9554 - val_loss: 0.0391 - val_accuracy: 0.9643\n",
      "Epoch 85/1000\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.94 - 0s 62us/step - loss: 0.0394 - accuracy: 0.9643 - val_loss: 0.0388 - val_accuracy: 0.9643\n",
      "Epoch 86/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0383 - accuracy: 0.9643 - val_loss: 0.0376 - val_accuracy: 0.9464\n",
      "Epoch 87/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0381 - accuracy: 0.9554 - val_loss: 0.0379 - val_accuracy: 0.9554\n",
      "Epoch 88/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0374 - accuracy: 0.9554 - val_loss: 0.0364 - val_accuracy: 0.9643\n",
      "Epoch 89/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0360 - accuracy: 0.9643 - val_loss: 0.0374 - val_accuracy: 0.9554\n",
      "Epoch 90/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0377 - accuracy: 0.9554 - val_loss: 0.0364 - val_accuracy: 0.9643\n",
      "Epoch 91/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0357 - accuracy: 0.9643 - val_loss: 0.0353 - val_accuracy: 0.9554\n",
      "Epoch 92/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0352 - accuracy: 0.9554 - val_loss: 0.0360 - val_accuracy: 0.9643\n",
      "Epoch 93/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0359 - accuracy: 0.9643 - val_loss: 0.0342 - val_accuracy: 0.9554\n",
      "Epoch 94/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0338 - accuracy: 0.9464 - val_loss: 0.0341 - val_accuracy: 0.9643\n",
      "Epoch 95/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0344 - accuracy: 0.9643 - val_loss: 0.0337 - val_accuracy: 0.9643\n",
      "Epoch 96/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0352 - accuracy: 0.9554 - val_loss: 0.0326 - val_accuracy: 0.9464\n",
      "Epoch 97/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0326 - accuracy: 0.9464 - val_loss: 0.0320 - val_accuracy: 0.9732\n",
      "Epoch 98/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0320 - accuracy: 0.9732 - val_loss: 0.0318 - val_accuracy: 0.9643\n",
      "Epoch 99/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0323 - accuracy: 0.9643 - val_loss: 0.0319 - val_accuracy: 0.9643\n",
      "Epoch 100/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0316 - accuracy: 0.9643 - val_loss: 0.0309 - val_accuracy: 0.9732\n",
      "Epoch 101/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0310 - accuracy: 0.9821 - val_loss: 0.0312 - val_accuracy: 0.9554\n",
      "Epoch 102/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0311 - accuracy: 0.9554 - val_loss: 0.0301 - val_accuracy: 0.9732\n",
      "Epoch 103/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0303 - accuracy: 0.9643 - val_loss: 0.0307 - val_accuracy: 0.9643\n",
      "Epoch 104/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0305 - accuracy: 0.9643 - val_loss: 0.0295 - val_accuracy: 0.9643\n",
      "Epoch 105/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0295 - accuracy: 0.9732 - val_loss: 0.0292 - val_accuracy: 0.9554\n",
      "Epoch 106/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0293 - accuracy: 0.9554 - val_loss: 0.0289 - val_accuracy: 0.9554\n",
      "Epoch 107/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0292 - accuracy: 0.9554 - val_loss: 0.0284 - val_accuracy: 0.9643\n",
      "Epoch 108/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0284 - accuracy: 0.9643 - val_loss: 0.0281 - val_accuracy: 0.9643\n",
      "Epoch 109/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0282 - accuracy: 0.9643 - val_loss: 0.0278 - val_accuracy: 0.9643\n",
      "Epoch 110/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0285 - accuracy: 0.9643 - val_loss: 0.0275 - val_accuracy: 0.9643\n",
      "Epoch 111/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0276 - accuracy: 0.9643 - val_loss: 0.0275 - val_accuracy: 0.9554\n",
      "Epoch 112/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0274 - accuracy: 0.9554 - val_loss: 0.0282 - val_accuracy: 0.9554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 113/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0282 - accuracy: 0.9554 - val_loss: 0.0269 - val_accuracy: 0.9554\n",
      "Epoch 114/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0275 - accuracy: 0.9554 - val_loss: 0.0265 - val_accuracy: 0.9643\n",
      "Epoch 115/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0265 - accuracy: 0.9643 - val_loss: 0.0261 - val_accuracy: 0.9643\n",
      "Epoch 116/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0261 - accuracy: 0.9643 - val_loss: 0.0260 - val_accuracy: 0.9732\n",
      "Epoch 117/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0264 - accuracy: 0.9643 - val_loss: 0.0260 - val_accuracy: 0.9554\n",
      "Epoch 118/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0261 - accuracy: 0.9643 - val_loss: 0.0255 - val_accuracy: 0.9643\n",
      "Epoch 119/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0255 - accuracy: 0.9643 - val_loss: 0.0253 - val_accuracy: 0.9643\n",
      "Epoch 120/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0252 - accuracy: 0.9643 - val_loss: 0.0250 - val_accuracy: 0.9732\n",
      "Epoch 121/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0249 - accuracy: 0.9732 - val_loss: 0.0250 - val_accuracy: 0.9643\n",
      "Epoch 122/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0250 - accuracy: 0.9643 - val_loss: 0.0247 - val_accuracy: 0.9643\n",
      "Epoch 123/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0246 - accuracy: 0.9732 - val_loss: 0.0244 - val_accuracy: 0.9643\n",
      "Epoch 124/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0243 - accuracy: 0.9643 - val_loss: 0.0252 - val_accuracy: 0.9643\n",
      "Epoch 125/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0255 - accuracy: 0.9643 - val_loss: 0.0248 - val_accuracy: 0.9643\n",
      "Epoch 126/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0242 - accuracy: 0.9643 - val_loss: 0.0240 - val_accuracy: 0.9554\n",
      "Epoch 127/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0248 - accuracy: 0.9554 - val_loss: 0.0251 - val_accuracy: 0.9554\n",
      "Epoch 128/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0246 - accuracy: 0.9554 - val_loss: 0.0233 - val_accuracy: 0.9643\n",
      "Epoch 129/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0253 - accuracy: 0.9643 - val_loss: 0.0243 - val_accuracy: 0.9643\n",
      "Epoch 130/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0240 - accuracy: 0.9643 - val_loss: 0.0230 - val_accuracy: 0.9732\n",
      "Epoch 131/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0231 - accuracy: 0.9643 - val_loss: 0.0236 - val_accuracy: 0.9554\n",
      "Epoch 132/1000\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0239 - accuracy: 0.94 - 0s 54us/step - loss: 0.0236 - accuracy: 0.9554 - val_loss: 0.0228 - val_accuracy: 0.9732\n",
      "Epoch 133/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0229 - accuracy: 0.9821 - val_loss: 0.0228 - val_accuracy: 0.9643\n",
      "Epoch 134/1000\n",
      "112/112 [==============================] - 0s 95us/step - loss: 0.0229 - accuracy: 0.9643 - val_loss: 0.0226 - val_accuracy: 0.9643\n",
      "Epoch 135/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0223 - accuracy: 0.9643 - val_loss: 0.0222 - val_accuracy: 0.9732\n",
      "Epoch 136/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0224 - accuracy: 0.9643 - val_loss: 0.0226 - val_accuracy: 0.9554\n",
      "Epoch 137/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0227 - accuracy: 0.9554 - val_loss: 0.0218 - val_accuracy: 0.9732\n",
      "Epoch 138/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0224 - accuracy: 0.9643 - val_loss: 0.0217 - val_accuracy: 0.9643\n",
      "Epoch 139/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0216 - accuracy: 0.9643 - val_loss: 0.0216 - val_accuracy: 0.9821\n",
      "Epoch 140/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0217 - accuracy: 0.9732 - val_loss: 0.0216 - val_accuracy: 0.9732\n",
      "Epoch 141/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0216 - accuracy: 0.9554 - val_loss: 0.0215 - val_accuracy: 0.9643\n",
      "Epoch 142/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0213 - accuracy: 0.9643 - val_loss: 0.0211 - val_accuracy: 0.9643\n",
      "Epoch 143/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0210 - accuracy: 0.9643 - val_loss: 0.0214 - val_accuracy: 0.9643\n",
      "Epoch 144/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0214 - accuracy: 0.9643 - val_loss: 0.0210 - val_accuracy: 0.9643\n",
      "Epoch 145/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0209 - accuracy: 0.9643 - val_loss: 0.0207 - val_accuracy: 0.9821\n",
      "Epoch 146/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0207 - accuracy: 0.9821 - val_loss: 0.0210 - val_accuracy: 0.9554\n",
      "Epoch 147/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0211 - accuracy: 0.9554 - val_loss: 0.0210 - val_accuracy: 0.9554\n",
      "Epoch 148/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0208 - accuracy: 0.9732 - val_loss: 0.0203 - val_accuracy: 0.9643\n",
      "Epoch 149/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0202 - accuracy: 0.9643 - val_loss: 0.0206 - val_accuracy: 0.9643\n",
      "Epoch 150/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0208 - accuracy: 0.9643 - val_loss: 0.0202 - val_accuracy: 0.9643\n",
      "Epoch 151/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0199 - accuracy: 0.9643 - val_loss: 0.0203 - val_accuracy: 0.9643\n",
      "Epoch 152/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0209 - accuracy: 0.9554 - val_loss: 0.0208 - val_accuracy: 0.9554\n",
      "Epoch 153/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0207 - accuracy: 0.9643 - val_loss: 0.0197 - val_accuracy: 0.9643\n",
      "Epoch 154/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0214 - accuracy: 0.9643 - val_loss: 0.0200 - val_accuracy: 0.9732\n",
      "Epoch 155/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0198 - accuracy: 0.9732 - val_loss: 0.0196 - val_accuracy: 0.9732\n",
      "Epoch 156/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0199 - accuracy: 0.9643 - val_loss: 0.0198 - val_accuracy: 0.9643\n",
      "Epoch 157/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0196 - accuracy: 0.9732 - val_loss: 0.0193 - val_accuracy: 0.9643\n",
      "Epoch 158/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0204 - accuracy: 0.9732 - val_loss: 0.0196 - val_accuracy: 0.9732\n",
      "Epoch 159/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0206 - accuracy: 0.9643 - val_loss: 0.0191 - val_accuracy: 0.9821\n",
      "Epoch 160/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0192 - accuracy: 0.9821 - val_loss: 0.0190 - val_accuracy: 0.9643\n",
      "Epoch 161/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0196 - accuracy: 0.9732 - val_loss: 0.0189 - val_accuracy: 0.9732\n",
      "Epoch 162/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0188 - accuracy: 0.9732 - val_loss: 0.0191 - val_accuracy: 0.9732\n",
      "Epoch 163/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0191 - accuracy: 0.9732 - val_loss: 0.0190 - val_accuracy: 0.9732\n",
      "Epoch 164/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0189 - accuracy: 0.9732 - val_loss: 0.0186 - val_accuracy: 0.9643\n",
      "Epoch 165/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0187 - accuracy: 0.9821 - val_loss: 0.0187 - val_accuracy: 0.9732\n",
      "Epoch 166/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0188 - accuracy: 0.9821 - val_loss: 0.0185 - val_accuracy: 0.9821\n",
      "Epoch 167/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0185 - accuracy: 0.9732 - val_loss: 0.0183 - val_accuracy: 0.9732\n",
      "Epoch 168/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 55us/step - loss: 0.0185 - accuracy: 0.9821 - val_loss: 0.0184 - val_accuracy: 0.9732\n",
      "Epoch 169/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0188 - accuracy: 0.9732 - val_loss: 0.0188 - val_accuracy: 0.9732\n",
      "Epoch 170/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0186 - accuracy: 0.9732 - val_loss: 0.0181 - val_accuracy: 0.9732\n",
      "Epoch 171/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0179 - accuracy: 0.9821 - val_loss: 0.0188 - val_accuracy: 0.9554\n",
      "Epoch 172/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0193 - accuracy: 0.9554 - val_loss: 0.0188 - val_accuracy: 0.9554\n",
      "Epoch 173/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0191 - accuracy: 0.9643 - val_loss: 0.0180 - val_accuracy: 0.9732\n",
      "Epoch 174/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0185 - accuracy: 0.9732 - val_loss: 0.0182 - val_accuracy: 0.9732\n",
      "Epoch 175/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0181 - accuracy: 0.9732 - val_loss: 0.0177 - val_accuracy: 0.9821\n",
      "Epoch 176/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0183 - accuracy: 0.9643 - val_loss: 0.0181 - val_accuracy: 0.9643\n",
      "Epoch 177/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0179 - accuracy: 0.9732 - val_loss: 0.0175 - val_accuracy: 0.9732\n",
      "Epoch 178/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0176 - accuracy: 0.9821 - val_loss: 0.0180 - val_accuracy: 0.9732\n",
      "Epoch 179/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0187 - accuracy: 0.9732 - val_loss: 0.0177 - val_accuracy: 0.9732\n",
      "Epoch 180/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0177 - accuracy: 0.9732 - val_loss: 0.0176 - val_accuracy: 0.9732\n",
      "Epoch 181/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0175 - accuracy: 0.9732 - val_loss: 0.0173 - val_accuracy: 0.9821\n",
      "Epoch 182/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0174 - accuracy: 0.9821 - val_loss: 0.0174 - val_accuracy: 0.9732\n",
      "Epoch 183/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0175 - accuracy: 0.9732 - val_loss: 0.0172 - val_accuracy: 0.9732\n",
      "Epoch 184/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0172 - accuracy: 0.9732 - val_loss: 0.0171 - val_accuracy: 0.9732\n",
      "Epoch 185/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0172 - accuracy: 0.9732 - val_loss: 0.0170 - val_accuracy: 0.9732\n",
      "Epoch 186/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0172 - accuracy: 0.9732 - val_loss: 0.0172 - val_accuracy: 0.9732\n",
      "Epoch 187/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0176 - accuracy: 0.9732 - val_loss: 0.0169 - val_accuracy: 0.9732\n",
      "Epoch 188/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0170 - accuracy: 0.9732 - val_loss: 0.0169 - val_accuracy: 0.9732\n",
      "Epoch 189/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0168 - accuracy: 0.9732 - val_loss: 0.0168 - val_accuracy: 0.9732\n",
      "Epoch 190/1000\n",
      "112/112 [==============================] - 0s 98us/step - loss: 0.0168 - accuracy: 0.9732 - val_loss: 0.0171 - val_accuracy: 0.9732\n",
      "Epoch 191/1000\n",
      "112/112 [==============================] - 0s 112us/step - loss: 0.0170 - accuracy: 0.9732 - val_loss: 0.0167 - val_accuracy: 0.9732\n",
      "Epoch 192/1000\n",
      "112/112 [==============================] - 0s 126us/step - loss: 0.0171 - accuracy: 0.9643 - val_loss: 0.0166 - val_accuracy: 0.9732\n",
      "Epoch 193/1000\n",
      "112/112 [==============================] - 0s 100us/step - loss: 0.0173 - accuracy: 0.9732 - val_loss: 0.0165 - val_accuracy: 0.9821\n",
      "Epoch 194/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0165 - accuracy: 0.9821 - val_loss: 0.0173 - val_accuracy: 0.9554\n",
      "Epoch 195/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0176 - accuracy: 0.9554 - val_loss: 0.0168 - val_accuracy: 0.9732\n",
      "Epoch 196/1000\n",
      "112/112 [==============================] - 0s 96us/step - loss: 0.0171 - accuracy: 0.9554 - val_loss: 0.0167 - val_accuracy: 0.9732\n",
      "Epoch 197/1000\n",
      "112/112 [==============================] - 0s 88us/step - loss: 0.0169 - accuracy: 0.9732 - val_loss: 0.0167 - val_accuracy: 0.9732\n",
      "Epoch 198/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0166 - accuracy: 0.9732 - val_loss: 0.0163 - val_accuracy: 0.9732\n",
      "Epoch 199/1000\n",
      "112/112 [==============================] - 0s 91us/step - loss: 0.0178 - accuracy: 0.9643 - val_loss: 0.0179 - val_accuracy: 0.9554\n",
      "Epoch 200/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0180 - accuracy: 0.9554 - val_loss: 0.0162 - val_accuracy: 0.9821\n",
      "Epoch 201/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0174 - accuracy: 0.9643 - val_loss: 0.0164 - val_accuracy: 0.9732\n",
      "Epoch 202/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0163 - accuracy: 0.9732 - val_loss: 0.0160 - val_accuracy: 0.9911\n",
      "Epoch 203/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0178 - accuracy: 0.9554 - val_loss: 0.0162 - val_accuracy: 0.9732\n",
      "Epoch 204/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0163 - accuracy: 0.9643 - val_loss: 0.0162 - val_accuracy: 0.9732\n",
      "Epoch 205/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0162 - accuracy: 0.9732 - val_loss: 0.0162 - val_accuracy: 0.9732\n",
      "Epoch 206/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0161 - accuracy: 0.9732 - val_loss: 0.0159 - val_accuracy: 0.9911\n",
      "Epoch 207/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0160 - accuracy: 0.9821 - val_loss: 0.0161 - val_accuracy: 0.9732\n",
      "Epoch 208/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0161 - accuracy: 0.9732 - val_loss: 0.0167 - val_accuracy: 0.9554\n",
      "Epoch 209/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0165 - accuracy: 0.9643 - val_loss: 0.0158 - val_accuracy: 0.9821\n",
      "Epoch 210/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0159 - accuracy: 0.9821 - val_loss: 0.0159 - val_accuracy: 0.9732\n",
      "Epoch 211/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0162 - accuracy: 0.9732 - val_loss: 0.0159 - val_accuracy: 0.9732\n",
      "Epoch 212/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0164 - accuracy: 0.9732 - val_loss: 0.0158 - val_accuracy: 0.9732\n",
      "Epoch 213/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0158 - accuracy: 0.9821 - val_loss: 0.0158 - val_accuracy: 0.9732\n",
      "Epoch 214/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0161 - accuracy: 0.9643 - val_loss: 0.0159 - val_accuracy: 0.9732\n",
      "Epoch 215/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0159 - accuracy: 0.9821 - val_loss: 0.0155 - val_accuracy: 0.9732\n",
      "Epoch 216/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0157 - accuracy: 0.9732 - val_loss: 0.0157 - val_accuracy: 0.9732\n",
      "Epoch 217/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0160 - accuracy: 0.9732 - val_loss: 0.0154 - val_accuracy: 0.9911\n",
      "Epoch 218/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0156 - accuracy: 0.9911 - val_loss: 0.0153 - val_accuracy: 0.9821\n",
      "Epoch 219/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0153 - accuracy: 0.9821 - val_loss: 0.0154 - val_accuracy: 0.9821\n",
      "Epoch 220/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0153 - accuracy: 0.9821 - val_loss: 0.0156 - val_accuracy: 0.9732\n",
      "Epoch 221/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0158 - accuracy: 0.9732 - val_loss: 0.0154 - val_accuracy: 0.9732\n",
      "Epoch 222/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0156 - accuracy: 0.9732 - val_loss: 0.0152 - val_accuracy: 0.9821\n",
      "Epoch 223/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0154 - accuracy: 0.9821 - val_loss: 0.0152 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 224/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0152 - accuracy: 0.9821 - val_loss: 0.0152 - val_accuracy: 0.9821\n",
      "Epoch 225/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0152 - accuracy: 0.9821 - val_loss: 0.0151 - val_accuracy: 0.9821\n",
      "Epoch 226/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0151 - accuracy: 0.9821 - val_loss: 0.0151 - val_accuracy: 0.9821\n",
      "Epoch 227/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0151 - accuracy: 0.9821 - val_loss: 0.0151 - val_accuracy: 0.9821\n",
      "Epoch 228/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0151 - accuracy: 0.9821 - val_loss: 0.0150 - val_accuracy: 0.9821\n",
      "Epoch 229/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0150 - accuracy: 0.9732 - val_loss: 0.0150 - val_accuracy: 0.9821\n",
      "Epoch 230/1000\n",
      "112/112 [==============================] - 0s 88us/step - loss: 0.0150 - accuracy: 0.9821 - val_loss: 0.0149 - val_accuracy: 0.9821\n",
      "Epoch 231/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0152 - accuracy: 0.9732 - val_loss: 0.0148 - val_accuracy: 0.9911\n",
      "Epoch 232/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0148 - accuracy: 0.9911 - val_loss: 0.0152 - val_accuracy: 0.9821\n",
      "Epoch 233/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0156 - accuracy: 0.9821 - val_loss: 0.0150 - val_accuracy: 0.9821\n",
      "Epoch 234/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0151 - accuracy: 0.9821 - val_loss: 0.0148 - val_accuracy: 0.9821\n",
      "Epoch 235/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0148 - accuracy: 0.9821 - val_loss: 0.0149 - val_accuracy: 0.9732\n",
      "Epoch 236/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0150 - accuracy: 0.9732 - val_loss: 0.0150 - val_accuracy: 0.9732\n",
      "Epoch 237/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0149 - accuracy: 0.9732 - val_loss: 0.0146 - val_accuracy: 0.9911\n",
      "Epoch 238/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0148 - accuracy: 0.9821 - val_loss: 0.0150 - val_accuracy: 0.9821\n",
      "Epoch 239/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0157 - accuracy: 0.9643 - val_loss: 0.0155 - val_accuracy: 0.9554\n",
      "Epoch 240/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0151 - accuracy: 0.9643 - val_loss: 0.0146 - val_accuracy: 0.9821\n",
      "Epoch 241/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0150 - accuracy: 0.9821 - val_loss: 0.0164 - val_accuracy: 0.9643\n",
      "Epoch 242/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0164 - accuracy: 0.9643 - val_loss: 0.0152 - val_accuracy: 0.9732\n",
      "Epoch 243/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0145 - accuracy: 0.9821 - val_loss: 0.0149 - val_accuracy: 0.9821\n",
      "Epoch 244/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0173 - accuracy: 0.9643 - val_loss: 0.0160 - val_accuracy: 0.9554\n",
      "Epoch 245/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0161 - accuracy: 0.9554 - val_loss: 0.0145 - val_accuracy: 0.9821\n",
      "Epoch 246/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0147 - accuracy: 0.9821 - val_loss: 0.0153 - val_accuracy: 0.9732\n",
      "Epoch 247/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0152 - accuracy: 0.9732 - val_loss: 0.0145 - val_accuracy: 0.9821\n",
      "Epoch 248/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0146 - accuracy: 0.9821 - val_loss: 0.0144 - val_accuracy: 0.9821\n",
      "Epoch 249/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0144 - accuracy: 0.9821 - val_loss: 0.0144 - val_accuracy: 0.9821\n",
      "Epoch 250/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0144 - accuracy: 0.9821 - val_loss: 0.0143 - val_accuracy: 0.9821\n",
      "Epoch 251/1000\n",
      "112/112 [==============================] - 0s 88us/step - loss: 0.0144 - accuracy: 0.9911 - val_loss: 0.0142 - val_accuracy: 0.9821\n",
      "Epoch 252/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0156 - accuracy: 0.9821 - val_loss: 0.0142 - val_accuracy: 0.9821\n",
      "Epoch 253/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0155 - accuracy: 0.9643 - val_loss: 0.0147 - val_accuracy: 0.9732\n",
      "Epoch 254/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0145 - accuracy: 0.9732 - val_loss: 0.0141 - val_accuracy: 0.9911\n",
      "Epoch 255/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0146 - accuracy: 0.9911 - val_loss: 0.0147 - val_accuracy: 0.9821\n",
      "Epoch 256/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0147 - accuracy: 0.9821 - val_loss: 0.0142 - val_accuracy: 0.9821\n",
      "Epoch 257/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0141 - accuracy: 0.9821 - val_loss: 0.0141 - val_accuracy: 0.9821\n",
      "Epoch 258/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0141 - accuracy: 0.9821 - val_loss: 0.0143 - val_accuracy: 0.9732\n",
      "Epoch 259/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0144 - accuracy: 0.9732 - val_loss: 0.0141 - val_accuracy: 0.9821\n",
      "Epoch 260/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0146 - accuracy: 0.9821 - val_loss: 0.0141 - val_accuracy: 0.9821\n",
      "Epoch 261/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0142 - accuracy: 0.9821 - val_loss: 0.0140 - val_accuracy: 0.9821\n",
      "Epoch 262/1000\n",
      "112/112 [==============================] - 0s 91us/step - loss: 0.0142 - accuracy: 0.9732 - val_loss: 0.0139 - val_accuracy: 0.9821\n",
      "Epoch 263/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0143 - accuracy: 0.9821 - val_loss: 0.0139 - val_accuracy: 0.9821\n",
      "Epoch 264/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0143 - accuracy: 0.9732 - val_loss: 0.0140 - val_accuracy: 0.9821\n",
      "Epoch 265/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0140 - accuracy: 0.9821 - val_loss: 0.0139 - val_accuracy: 0.9911\n",
      "Epoch 266/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0138 - accuracy: 0.9911 - val_loss: 0.0140 - val_accuracy: 0.9821\n",
      "Epoch 267/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0152 - accuracy: 0.9643 - val_loss: 0.0142 - val_accuracy: 0.9821\n",
      "Epoch 268/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0138 - accuracy: 0.9821 - val_loss: 0.0140 - val_accuracy: 0.9821\n",
      "Epoch 269/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0139 - accuracy: 0.9821 - val_loss: 0.0152 - val_accuracy: 0.9643\n",
      "Epoch 270/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0152 - accuracy: 0.9643 - val_loss: 0.0143 - val_accuracy: 0.9732\n",
      "Epoch 271/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0140 - accuracy: 0.9732 - val_loss: 0.0138 - val_accuracy: 0.9821\n",
      "Epoch 272/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0140 - accuracy: 0.9821 - val_loss: 0.0148 - val_accuracy: 0.9643\n",
      "Epoch 273/1000\n",
      "112/112 [==============================] - 0s 100us/step - loss: 0.0148 - accuracy: 0.9732 - val_loss: 0.0138 - val_accuracy: 0.9821\n",
      "Epoch 274/1000\n",
      "112/112 [==============================] - 0s 101us/step - loss: 0.0142 - accuracy: 0.9821 - val_loss: 0.0137 - val_accuracy: 0.9821\n",
      "Epoch 275/1000\n",
      "112/112 [==============================] - 0s 113us/step - loss: 0.0140 - accuracy: 0.9821 - val_loss: 0.0137 - val_accuracy: 0.9821\n",
      "Epoch 276/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0137 - accuracy: 0.9732 - val_loss: 0.0138 - val_accuracy: 0.9821\n",
      "Epoch 277/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0139 - accuracy: 0.9821 - val_loss: 0.0139 - val_accuracy: 0.9821\n",
      "Epoch 278/1000\n",
      "112/112 [==============================] - 0s 88us/step - loss: 0.0145 - accuracy: 0.9821 - val_loss: 0.0137 - val_accuracy: 0.9821\n",
      "Epoch 279/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0141 - accuracy: 0.9732 - val_loss: 0.0141 - val_accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 280/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0141 - accuracy: 0.9732 - val_loss: 0.0138 - val_accuracy: 0.9821\n",
      "Epoch 281/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0137 - accuracy: 0.9821 - val_loss: 0.0135 - val_accuracy: 0.9821\n",
      "Epoch 282/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0134 - accuracy: 0.9821 - val_loss: 0.0141 - val_accuracy: 0.9821\n",
      "Epoch 283/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0141 - accuracy: 0.9821 - val_loss: 0.0140 - val_accuracy: 0.9821\n",
      "Epoch 284/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0138 - accuracy: 0.9821 - val_loss: 0.0134 - val_accuracy: 0.9821\n",
      "Epoch 285/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0135 - accuracy: 0.9911 - val_loss: 0.0143 - val_accuracy: 0.9643\n",
      "Epoch 286/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0147 - accuracy: 0.9643 - val_loss: 0.0138 - val_accuracy: 0.9732\n",
      "Epoch 287/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0135 - accuracy: 0.9821 - val_loss: 0.0138 - val_accuracy: 0.9821\n",
      "Epoch 288/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0139 - accuracy: 0.9732 - val_loss: 0.0143 - val_accuracy: 0.9643\n",
      "Epoch 289/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0143 - accuracy: 0.9732 - val_loss: 0.0133 - val_accuracy: 0.9821\n",
      "Epoch 290/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0148 - accuracy: 0.9643 - val_loss: 0.0136 - val_accuracy: 0.9821\n",
      "Epoch 291/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0135 - accuracy: 0.9821 - val_loss: 0.0133 - val_accuracy: 0.9821\n",
      "Epoch 292/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0132 - accuracy: 0.9821 - val_loss: 0.0141 - val_accuracy: 0.9643\n",
      "Epoch 293/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0142 - accuracy: 0.9643 - val_loss: 0.0137 - val_accuracy: 0.9821\n",
      "Epoch 294/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0134 - accuracy: 0.9821 - val_loss: 0.0133 - val_accuracy: 0.9821\n",
      "Epoch 295/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0133 - accuracy: 0.9821 - val_loss: 0.0141 - val_accuracy: 0.9643\n",
      "Epoch 296/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0148 - accuracy: 0.9643 - val_loss: 0.0136 - val_accuracy: 0.9732\n",
      "Epoch 297/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0132 - accuracy: 0.9732 - val_loss: 0.0140 - val_accuracy: 0.9732\n",
      "Epoch 298/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0149 - accuracy: 0.9643 - val_loss: 0.0151 - val_accuracy: 0.9554\n",
      "Epoch 299/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0160 - accuracy: 0.9554 - val_loss: 0.0131 - val_accuracy: 0.9821\n",
      "Epoch 300/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0136 - accuracy: 0.9821 - val_loss: 0.0134 - val_accuracy: 0.9821\n",
      "Epoch 301/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0134 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9821\n",
      "Epoch 302/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0132 - val_accuracy: 0.9821\n",
      "Epoch 303/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0134 - accuracy: 0.9821 - val_loss: 0.0132 - val_accuracy: 0.9821\n",
      "Epoch 304/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0136 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9821\n",
      "Epoch 305/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 306/1000\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0123 - accuracy: 0.98 - 0s 61us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 307/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 308/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 309/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0133 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 310/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0130 - accuracy: 0.9911 - val_loss: 0.0132 - val_accuracy: 0.9821\n",
      "Epoch 311/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0132 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9821\n",
      "Epoch 312/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0135 - accuracy: 0.9732 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 313/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 314/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9911\n",
      "Epoch 315/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0137 - accuracy: 0.9732 - val_loss: 0.0132 - val_accuracy: 0.9821\n",
      "Epoch 316/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0144 - accuracy: 0.9732 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 317/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 318/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 319/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0131 - accuracy: 0.9911 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 320/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 321/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0139 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 322/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 323/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0131 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 324/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0132 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 325/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0129 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 326/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0127 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 327/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0127 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 328/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0133 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 329/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0137 - accuracy: 0.9732 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 330/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 331/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 332/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9911\n",
      "Epoch 333/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0128 - accuracy: 0.9911 - val_loss: 0.0130 - val_accuracy: 0.9821\n",
      "Epoch 334/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0129 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 335/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 63us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 336/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0134 - val_accuracy: 0.9821\n",
      "Epoch 337/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0134 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 338/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 339/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0131 - accuracy: 0.9732 - val_loss: 0.0126 - val_accuracy: 0.9911\n",
      "Epoch 340/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0126 - accuracy: 0.9911 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 341/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 342/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 343/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0128 - accuracy: 0.9732 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 344/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 345/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0130 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 346/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0127 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9911\n",
      "Epoch 347/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 348/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9821\n",
      "Epoch 349/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 350/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 351/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9821\n",
      "Epoch 352/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 353/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0132 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 354/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 355/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0129 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 356/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 357/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0127 - accuracy: 0.9732 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 358/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 359/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 360/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0136 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 361/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0133 - val_accuracy: 0.9643\n",
      "Epoch 362/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0133 - accuracy: 0.9732 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 363/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 364/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 365/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 366/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 367/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 368/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 369/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9911\n",
      "Epoch 370/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9732\n",
      "Epoch 371/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0132 - accuracy: 0.9732 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 372/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 373/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 374/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 375/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 376/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9821\n",
      "Epoch 377/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 378/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0133 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 379/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 380/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0134 - val_accuracy: 0.9643\n",
      "Epoch 381/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0142 - accuracy: 0.9643 - val_loss: 0.0135 - val_accuracy: 0.9643\n",
      "Epoch 382/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0130 - accuracy: 0.9732 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 383/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0137 - val_accuracy: 0.9643\n",
      "Epoch 384/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0144 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 385/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 386/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 387/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0130 - accuracy: 0.9732 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 388/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 389/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0130 - accuracy: 0.9732 - val_loss: 0.0125 - val_accuracy: 0.9821\n",
      "Epoch 390/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0147 - accuracy: 0.9732 - val_loss: 0.0133 - val_accuracy: 0.9643\n",
      "Epoch 392/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0128 - accuracy: 0.9732 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 393/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0130 - accuracy: 0.9732 - val_loss: 0.0136 - val_accuracy: 0.9643\n",
      "Epoch 394/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0140 - accuracy: 0.9643 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 395/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0122 - accuracy: 0.9911 - val_loss: 0.0138 - val_accuracy: 0.9643\n",
      "Epoch 396/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0139 - accuracy: 0.9643 - val_loss: 0.0139 - val_accuracy: 0.9643\n",
      "Epoch 397/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0135 - accuracy: 0.9643 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 398/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0127 - accuracy: 0.9821 - val_loss: 0.0132 - val_accuracy: 0.9643\n",
      "Epoch 399/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0133 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 400/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9911\n",
      "Epoch 401/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9732\n",
      "Epoch 402/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 403/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 404/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 405/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9643\n",
      "Epoch 406/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0131 - accuracy: 0.9643 - val_loss: 0.0139 - val_accuracy: 0.9643\n",
      "Epoch 407/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0138 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 408/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0119 - accuracy: 0.9732 - val_loss: 0.0126 - val_accuracy: 0.9821\n",
      "Epoch 409/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0133 - accuracy: 0.9821 - val_loss: 0.0135 - val_accuracy: 0.9643\n",
      "Epoch 410/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0131 - accuracy: 0.9643 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 411/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9732\n",
      "Epoch 412/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0131 - accuracy: 0.9732 - val_loss: 0.0123 - val_accuracy: 0.9821\n",
      "Epoch 413/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 414/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 415/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9643\n",
      "Epoch 416/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 417/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9732\n",
      "Epoch 418/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0127 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9732\n",
      "Epoch 419/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 420/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 421/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 422/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 423/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 424/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 425/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 426/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 427/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 428/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 429/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 430/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 431/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 432/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0127 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 433/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 434/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 435/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0126 - accuracy: 0.9732 - val_loss: 0.0122 - val_accuracy: 0.9821\n",
      "Epoch 436/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0118 - accuracy: 0.9732 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 437/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9643\n",
      "Epoch 438/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0129 - accuracy: 0.9643 - val_loss: 0.0128 - val_accuracy: 0.9643\n",
      "Epoch 439/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0126 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 440/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 441/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0137 - accuracy: 0.9732 - val_loss: 0.0123 - val_accuracy: 0.9732\n",
      "Epoch 442/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0116 - accuracy: 0.9732 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 443/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0137 - accuracy: 0.9732 - val_loss: 0.0134 - val_accuracy: 0.9643\n",
      "Epoch 444/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0138 - accuracy: 0.9643 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 445/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9732\n",
      "Epoch 446/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0123 - accuracy: 0.9732 - val_loss: 0.0119 - val_accuracy: 0.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 447/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0118 - accuracy: 0.9911 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 448/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 449/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 450/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9732\n",
      "Epoch 451/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0125 - val_accuracy: 0.9732\n",
      "Epoch 452/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0129 - accuracy: 0.9643 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 453/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 454/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 455/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 456/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 457/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 458/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 459/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 460/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9821\n",
      "Epoch 461/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 462/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 463/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 464/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 465/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 466/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 467/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 468/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 469/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9911\n",
      "Epoch 470/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0119 - accuracy: 0.9911 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 471/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0123 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 472/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9643\n",
      "Epoch 473/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0150 - accuracy: 0.9643 - val_loss: 0.0132 - val_accuracy: 0.9643\n",
      "Epoch 474/1000\n",
      "112/112 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.97 - 0s 66us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9911\n",
      "Epoch 475/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0138 - val_accuracy: 0.9643\n",
      "Epoch 476/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0144 - accuracy: 0.9643 - val_loss: 0.0127 - val_accuracy: 0.9732\n",
      "Epoch 477/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0124 - val_accuracy: 0.9821\n",
      "Epoch 478/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0142 - accuracy: 0.9732 - val_loss: 0.0143 - val_accuracy: 0.9643\n",
      "Epoch 479/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0136 - accuracy: 0.9643 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 480/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0130 - val_accuracy: 0.9643\n",
      "Epoch 481/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0135 - accuracy: 0.9643 - val_loss: 0.0138 - val_accuracy: 0.9643\n",
      "Epoch 482/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0131 - accuracy: 0.9643 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 483/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0136 - val_accuracy: 0.9643\n",
      "Epoch 484/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0140 - accuracy: 0.9643 - val_loss: 0.0143 - val_accuracy: 0.9643\n",
      "Epoch 485/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0136 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 486/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0131 - val_accuracy: 0.9643\n",
      "Epoch 487/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0133 - accuracy: 0.9643 - val_loss: 0.0146 - val_accuracy: 0.9643\n",
      "Epoch 488/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0147 - accuracy: 0.9643 - val_loss: 0.0118 - val_accuracy: 0.9911\n",
      "Epoch 489/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0123 - accuracy: 0.9911 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 490/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 491/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 492/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 493/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 494/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 495/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 496/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 497/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 498/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 499/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 500/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9911\n",
      "Epoch 501/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0116 - accuracy: 0.9911 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 502/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112/112 [==============================] - 0s 212us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 503/1000\n",
      "112/112 [==============================] - 0s 154us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 504/1000\n",
      "112/112 [==============================] - 0s 98us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 505/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 506/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 507/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 508/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 509/1000\n",
      "112/112 [==============================] - 0s 95us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 510/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 511/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 512/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 513/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 514/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 515/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 516/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 517/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 518/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 519/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 520/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 521/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 522/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 523/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 524/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0123 - accuracy: 0.9643 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 525/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 526/1000\n",
      "112/112 [==============================] - 0s 88us/step - loss: 0.0123 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9643\n",
      "Epoch 527/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0135 - accuracy: 0.9643 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 528/1000\n",
      "112/112 [==============================] - 0s 99us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 529/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 530/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 531/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 532/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 533/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 534/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0123 - val_accuracy: 0.9732\n",
      "Epoch 535/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0122 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 536/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 537/1000\n",
      "112/112 [==============================] - 0s 93us/step - loss: 0.0121 - accuracy: 0.9643 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 538/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 539/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 540/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0133 - accuracy: 0.9643 - val_loss: 0.0118 - val_accuracy: 0.9732\n",
      "Epoch 541/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 542/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9821\n",
      "Epoch 543/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 544/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 545/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 546/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 547/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 548/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 549/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 550/1000\n",
      "112/112 [==============================] - 0s 95us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 551/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 552/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0129 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 553/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 554/1000\n",
      "112/112 [==============================] - 0s 87us/step - loss: 0.0131 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 555/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 556/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 557/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 558/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 559/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 560/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 561/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 562/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 563/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9732\n",
      "Epoch 564/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0118 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 565/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 566/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0123 - val_accuracy: 0.9643\n",
      "Epoch 567/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0125 - accuracy: 0.9643 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 568/1000\n",
      "112/112 [==============================] - 0s 91us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 569/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 570/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 571/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 572/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 573/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 574/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 575/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 576/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 577/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 578/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9643\n",
      "Epoch 579/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 580/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 581/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 582/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 583/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 584/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 585/1000\n",
      "112/112 [==============================] - 0s 117us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 586/1000\n",
      "112/112 [==============================] - 0s 84us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 587/1000\n",
      "112/112 [==============================] - 0s 76us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 588/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 589/1000\n",
      "112/112 [==============================] - 0s 93us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 590/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0119 - accuracy: 0.9732 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 591/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 592/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 593/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 594/1000\n",
      "112/112 [==============================] - 0s 122us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 595/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 596/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 597/1000\n",
      "112/112 [==============================] - 0s 97us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 598/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 599/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 600/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 601/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 602/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 603/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 604/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 605/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 606/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 607/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 608/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 609/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 610/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 611/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 612/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 613/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 614/1000\n",
      "112/112 [==============================] - 0s 93us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9732\n",
      "Epoch 615/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0122 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 616/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 617/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 618/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 619/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 620/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 621/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 622/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 623/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 624/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 625/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 626/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 627/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 628/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 629/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 630/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 631/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 632/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 633/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0123 - accuracy: 0.9732 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 634/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 635/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 636/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 637/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 638/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 639/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 640/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 641/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 642/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 643/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 644/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 645/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 646/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0119 - accuracy: 0.9643 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 647/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9643\n",
      "Epoch 648/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0122 - accuracy: 0.9643 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 649/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 650/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9732\n",
      "Epoch 651/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 652/1000\n",
      "112/112 [==============================] - 0s 100us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 653/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 654/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 655/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 656/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 657/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 658/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 659/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0119 - accuracy: 0.9732 - val_loss: 0.0117 - val_accuracy: 0.9821\n",
      "Epoch 660/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 661/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 662/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 663/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 664/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 665/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 666/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 667/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 668/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 669/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 670/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 671/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 672/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 673/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 674/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 675/1000\n",
      "112/112 [==============================] - 0s 51us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 676/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 677/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 678/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0125 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 679/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 680/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0121 - accuracy: 0.9821 - val_loss: 0.0127 - val_accuracy: 0.9732\n",
      "Epoch 681/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 682/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 683/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0123 - val_accuracy: 0.9643\n",
      "Epoch 684/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0122 - accuracy: 0.9643 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 685/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0134 - accuracy: 0.9643 - val_loss: 0.0124 - val_accuracy: 0.9732\n",
      "Epoch 686/1000\n",
      "112/112 [==============================] - 0s 52us/step - loss: 0.0122 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 687/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 688/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 689/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 690/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 691/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 692/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 693/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 694/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 695/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 696/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 697/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0123 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 698/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 699/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 700/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 701/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 702/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9732\n",
      "Epoch 703/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0123 - accuracy: 0.9732 - val_loss: 0.0122 - val_accuracy: 0.9732\n",
      "Epoch 704/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0118 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 705/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 706/1000\n",
      "112/112 [==============================] - 0s 93us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 707/1000\n",
      "112/112 [==============================] - 0s 133us/step - loss: 0.0127 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 708/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 709/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 710/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 711/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 712/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0127 - accuracy: 0.9732 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 713/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 714/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9732\n",
      "Epoch 715/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 716/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 717/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 718/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 719/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 720/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 721/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 722/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 723/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 724/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 725/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 726/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 727/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 728/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 729/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 730/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 731/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 732/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 733/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9643\n",
      "Epoch 734/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0128 - accuracy: 0.9643 - val_loss: 0.0116 - val_accuracy: 0.9732\n",
      "Epoch 735/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0114 - accuracy: 0.9643 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 736/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 737/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 738/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 739/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0111 - accuracy: 0.9732 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 740/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 741/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9821\n",
      "Epoch 742/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0122 - accuracy: 0.9732 - val_loss: 0.0139 - val_accuracy: 0.9643\n",
      "Epoch 743/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0134 - accuracy: 0.9643 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 744/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0117 - val_accuracy: 0.9732\n",
      "Epoch 745/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0121 - val_accuracy: 0.9732\n",
      "Epoch 746/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0116 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 747/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9643\n",
      "Epoch 748/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0123 - accuracy: 0.9643 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 749/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 750/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 751/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 752/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0109 - accuracy: 0.9911 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 753/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0114 - accuracy: 0.9732 - val_loss: 0.0128 - val_accuracy: 0.9643\n",
      "Epoch 754/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0129 - accuracy: 0.9643 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 755/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 756/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0118 - accuracy: 0.9732 - val_loss: 0.0124 - val_accuracy: 0.9732\n",
      "Epoch 757/1000\n",
      "112/112 [==============================] - 0s 90us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 758/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 759/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 760/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 761/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 762/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 763/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 764/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 765/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 766/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 767/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 768/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 769/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 770/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 771/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0118 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 772/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 773/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 774/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 775/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 776/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 777/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 778/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 779/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 780/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 781/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 782/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 783/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 784/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 785/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 786/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 787/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 788/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 789/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 790/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0117 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 791/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 792/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 793/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9732\n",
      "Epoch 794/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0119 - accuracy: 0.9732 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 795/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0120 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 796/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 797/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 798/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 799/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 800/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 801/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 802/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 803/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 804/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 805/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 806/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 807/1000\n",
      "112/112 [==============================] - 0s 155us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 808/1000\n",
      "112/112 [==============================] - 0s 105us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 809/1000\n",
      "112/112 [==============================] - 0s 110us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 810/1000\n",
      "112/112 [==============================] - 0s 99us/step - loss: 0.0124 - accuracy: 0.9732 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 811/1000\n",
      "112/112 [==============================] - 0s 100us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9821\n",
      "Epoch 812/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9643\n",
      "Epoch 813/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0127 - accuracy: 0.9643 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 814/1000\n",
      "112/112 [==============================] - 0s 94us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 815/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 816/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 817/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9643\n",
      "Epoch 818/1000\n",
      "112/112 [==============================] - 0s 85us/step - loss: 0.0122 - accuracy: 0.9643 - val_loss: 0.0118 - val_accuracy: 0.9821\n",
      "Epoch 819/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 820/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9732\n",
      "Epoch 821/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0122 - accuracy: 0.9732 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 822/1000\n",
      "112/112 [==============================] - 0s 83us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 823/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 824/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 825/1000\n",
      "112/112 [==============================] - 0s 77us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 826/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 827/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 828/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 829/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0122 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 830/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 831/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 832/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 833/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 834/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 835/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 836/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 837/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 838/1000\n",
      "112/112 [==============================] - 0s 70us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 839/1000\n",
      "112/112 [==============================] - 0s 79us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 840/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 841/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 842/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 843/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 844/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0115 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 845/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 846/1000\n",
      "112/112 [==============================] - 0s 89us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 847/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 848/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 849/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 850/1000\n",
      "112/112 [==============================] - 0s 75us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 851/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 852/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 853/1000\n",
      "112/112 [==============================] - 0s 109us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 854/1000\n",
      "112/112 [==============================] - 0s 96us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 855/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 856/1000\n",
      "112/112 [==============================] - 0s 78us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 857/1000\n",
      "112/112 [==============================] - 0s 80us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 858/1000\n",
      "112/112 [==============================] - 0s 69us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 859/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 860/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 861/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 862/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 863/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0124 - accuracy: 0.9643 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 864/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 865/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0115 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9732\n",
      "Epoch 866/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 867/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 868/1000\n",
      "112/112 [==============================] - 0s 74us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 869/1000\n",
      "112/112 [==============================] - 0s 71us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 870/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 871/1000\n",
      "112/112 [==============================] - 0s 92us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 872/1000\n",
      "112/112 [==============================] - 0s 67us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 873/1000\n",
      "112/112 [==============================] - 0s 86us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9643\n",
      "Epoch 874/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0128 - accuracy: 0.9643 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 875/1000\n",
      "112/112 [==============================] - 0s 87us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9732\n",
      "Epoch 876/1000\n",
      "112/112 [==============================] - 0s 81us/step - loss: 0.0128 - accuracy: 0.9732 - val_loss: 0.0132 - val_accuracy: 0.9643\n",
      "Epoch 877/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0126 - accuracy: 0.9732 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 878/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0128 - val_accuracy: 0.9643\n",
      "Epoch 879/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0131 - accuracy: 0.9643 - val_loss: 0.0130 - val_accuracy: 0.9643\n",
      "Epoch 880/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 881/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0099 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 882/1000\n",
      "112/112 [==============================] - 0s 82us/step - loss: 0.0125 - accuracy: 0.9732 - val_loss: 0.0134 - val_accuracy: 0.9643\n",
      "Epoch 883/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0134 - accuracy: 0.9643 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 884/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0100 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 885/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0123 - accuracy: 0.9732 - val_loss: 0.0127 - val_accuracy: 0.9643\n",
      "Epoch 886/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0126 - accuracy: 0.9643 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 887/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0116 - val_accuracy: 0.9732\n",
      "Epoch 888/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 889/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0109 - accuracy: 0.9911 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 890/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0128 - accuracy: 0.9732 - val_loss: 0.0122 - val_accuracy: 0.9643\n",
      "Epoch 891/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0119 - accuracy: 0.9643 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 892/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 893/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9732\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 894/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0117 - accuracy: 0.9732 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 895/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0129 - val_accuracy: 0.9643\n",
      "Epoch 896/1000\n",
      "112/112 [==============================] - 0s 65us/step - loss: 0.0130 - accuracy: 0.9732 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 897/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 898/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 899/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 900/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 901/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 902/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 903/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 904/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 905/1000\n",
      "112/112 [==============================] - 0s 72us/step - loss: 0.0111 - accuracy: 0.9732 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 906/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 907/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 908/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 909/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 910/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 911/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 912/1000\n",
      "112/112 [==============================] - 0s 62us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0112 - val_accuracy: 0.9821\n",
      "Epoch 913/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0125 - val_accuracy: 0.9643\n",
      "Epoch 914/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0126 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 915/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 916/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0113 - val_accuracy: 0.9821\n",
      "Epoch 917/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9732\n",
      "Epoch 918/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 919/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 920/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 921/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 922/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0124 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 923/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 924/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 925/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0111 - val_accuracy: 0.9821\n",
      "Epoch 926/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 927/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0128 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 928/1000\n",
      "112/112 [==============================] - 0s 52us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 929/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 930/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 931/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 932/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 933/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0139 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 934/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 935/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9732\n",
      "Epoch 936/1000\n",
      "112/112 [==============================] - 0s 53us/step - loss: 0.0112 - accuracy: 0.9732 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 937/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 938/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0120 - val_accuracy: 0.9643\n",
      "Epoch 939/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0121 - accuracy: 0.9643 - val_loss: 0.0120 - val_accuracy: 0.9643\n",
      "Epoch 940/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0120 - accuracy: 0.9732 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 941/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 942/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0115 - accuracy: 0.9732 - val_loss: 0.0112 - val_accuracy: 0.9732\n",
      "Epoch 943/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0111 - accuracy: 0.9732 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 944/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0102 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 945/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0114 - val_accuracy: 0.9821\n",
      "Epoch 946/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0112 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 947/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 948/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 949/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 950/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0119 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9821\n",
      "Epoch 951/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 952/1000\n",
      "112/112 [==============================] - 0s 93us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 953/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 954/1000\n",
      "112/112 [==============================] - 0s 87us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 955/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 956/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 957/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 958/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 959/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9732\n",
      "Epoch 960/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0112 - accuracy: 0.9732 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 961/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 962/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 963/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 964/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0107 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 965/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0105 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 966/1000\n",
      "112/112 [==============================] - 0s 60us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 967/1000\n",
      "112/112 [==============================] - 0s 91us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 968/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0109 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 969/1000\n",
      "112/112 [==============================] - 0s 73us/step - loss: 0.0110 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 970/1000\n",
      "112/112 [==============================] - 0s 63us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 971/1000\n",
      "112/112 [==============================] - 0s 68us/step - loss: 0.0108 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 972/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0104 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 973/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 974/1000\n",
      "112/112 [==============================] - 0s 61us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 975/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0110 - val_accuracy: 0.9732\n",
      "Epoch 976/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0116 - accuracy: 0.9643 - val_loss: 0.0110 - val_accuracy: 0.9732\n",
      "Epoch 977/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 978/1000\n",
      "112/112 [==============================] - 0s 64us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0119 - val_accuracy: 0.9643\n",
      "Epoch 979/1000\n",
      "112/112 [==============================] - 0s 66us/step - loss: 0.0118 - accuracy: 0.9643 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 980/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0111 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 981/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0106 - val_accuracy: 0.9821\n",
      "Epoch 982/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 983/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0115 - accuracy: 0.9732 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 984/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0103 - accuracy: 0.9821 - val_loss: 0.0108 - val_accuracy: 0.9821\n",
      "Epoch 985/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0124 - accuracy: 0.9643 - val_loss: 0.0115 - val_accuracy: 0.9821\n",
      "Epoch 986/1000\n",
      "112/112 [==============================] - 0s 58us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 987/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0096 - accuracy: 0.9911 - val_loss: 0.0140 - val_accuracy: 0.9643\n",
      "Epoch 988/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0161 - accuracy: 0.9643 - val_loss: 0.0150 - val_accuracy: 0.9643\n",
      "Epoch 989/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0140 - accuracy: 0.9643 - val_loss: 0.0104 - val_accuracy: 0.9821\n",
      "Epoch 990/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0097 - accuracy: 0.9821 - val_loss: 0.0143 - val_accuracy: 0.9643\n",
      "Epoch 991/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0144 - accuracy: 0.9643 - val_loss: 0.0147 - val_accuracy: 0.9643\n",
      "Epoch 992/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0139 - accuracy: 0.9643 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 993/1000\n",
      "112/112 [==============================] - 0s 56us/step - loss: 0.0116 - accuracy: 0.9821 - val_loss: 0.0121 - val_accuracy: 0.9732\n",
      "Epoch 994/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0133 - accuracy: 0.9643 - val_loss: 0.0120 - val_accuracy: 0.9732\n",
      "Epoch 995/1000\n",
      "112/112 [==============================] - 0s 54us/step - loss: 0.0114 - accuracy: 0.9821 - val_loss: 0.0105 - val_accuracy: 0.9821\n",
      "Epoch 996/1000\n",
      "112/112 [==============================] - 0s 59us/step - loss: 0.0113 - accuracy: 0.9821 - val_loss: 0.0122 - val_accuracy: 0.9643\n",
      "Epoch 997/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0121 - accuracy: 0.9732 - val_loss: 0.0109 - val_accuracy: 0.9821\n",
      "Epoch 998/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0106 - accuracy: 0.9821 - val_loss: 0.0107 - val_accuracy: 0.9821\n",
      "Epoch 999/1000\n",
      "112/112 [==============================] - 0s 55us/step - loss: 0.0110 - accuracy: 0.9732 - val_loss: 0.0111 - val_accuracy: 0.9732\n",
      "Epoch 1000/1000\n",
      "112/112 [==============================] - 0s 57us/step - loss: 0.0115 - accuracy: 0.9732 - val_loss: 0.0104 - val_accuracy: 0.9821\n"
     ]
    }
   ],
   "source": [
    "'Defining the model'\n",
    "# TODO\n",
    "model = Sequential()\n",
    "model.add(Dense(500, input_dim=4, activation='sigmoid'))\n",
    "model.add(Dense(100, activation='sigmoid'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "'Train your model...'\n",
    "'Store the cost (or loss), so that you can use it to plot the graph'\n",
    "# You might want to check out this: https://keras.io/callbacks/#create-a-callback\n",
    "# TODO\n",
    "history_callback = model.fit(x_train,y_train, epochs=1000, batch_size=70, validation_data=(x_train, y_train))\n",
    "loss_history = history_callback.history[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UfQMkkiCIApV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'Plot loss'\n",
    "# TODO\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"No. of iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# A sample code is provided below. \n",
    "\n",
    "#plt.plot(iter, loss_hist)\n",
    "#plt.xlabel(\"No. of iterations\")\n",
    "#plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJgoZhAzIApa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1         Iris-setosa\n",
       "2         Iris-setosa\n",
       "3         Iris-setosa\n",
       "4         Iris-setosa\n",
       "5         Iris-setosa\n",
       "6         Iris-setosa\n",
       "7         Iris-setosa\n",
       "8         Iris-setosa\n",
       "9         Iris-setosa\n",
       "10        Iris-setosa\n",
       "11        Iris-setosa\n",
       "12        Iris-setosa\n",
       "13        Iris-setosa\n",
       "14    Iris-versicolor\n",
       "15    Iris-versicolor\n",
       "16    Iris-versicolor\n",
       "17    Iris-versicolor\n",
       "18    Iris-versicolor\n",
       "19    Iris-versicolor\n",
       "20    Iris-versicolor\n",
       "21    Iris-versicolor\n",
       "22    Iris-versicolor\n",
       "23    Iris-versicolor\n",
       "24    Iris-versicolor\n",
       "25    Iris-versicolor\n",
       "26    Iris-versicolor\n",
       "27     Iris-virginica\n",
       "28     Iris-virginica\n",
       "29     Iris-virginica\n",
       "30     Iris-virginica\n",
       "31     Iris-virginica\n",
       "32     Iris-virginica\n",
       "33     Iris-virginica\n",
       "34     Iris-virginica\n",
       "35     Iris-virginica\n",
       "36     Iris-virginica\n",
       "37     Iris-virginica\n",
       "38     Iris-virginica\n",
       "Name: prediction, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Test the neural network'\n",
    "# Here you have to find out predicted output for every data from your test dataset\n",
    "# TODO\n",
    "test_prediction = []\n",
    "\n",
    "for row in range(len(test_df)):\n",
    "    test = np.array([x_test[row]])\n",
    "    result = model.predict_classes(test)\n",
    "    if result==0:\n",
    "        test_prediction.append(\"Iris-setosa\")\n",
    "    elif result==1:\n",
    "        test_prediction.append(\"Iris-versicolor\")\n",
    "    elif result==2:\n",
    "        test_prediction.append(\"Iris-virginica\")\n",
    "\n",
    "test_df['prediction'] = test_prediction\n",
    "test_df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jVrH6yDzIApc"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.1</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.5</td>\n",
       "      <td>2.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.6</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.3</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.8</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>5.3</td>\n",
       "      <td>3.7</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.5</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6.1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>5.6</td>\n",
       "      <td>2.7</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>5.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.2</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6.2</td>\n",
       "      <td>2.9</td>\n",
       "      <td>4.3</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>5.1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.1</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.7</td>\n",
       "      <td>2.8</td>\n",
       "      <td>4.1</td>\n",
       "      <td>1.3</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.8</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.6</td>\n",
       "      <td>2.4</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>6.9</td>\n",
       "      <td>3.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.7</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>6.8</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.9</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.3</td>\n",
       "      <td>5.7</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sepal_length  sepal_width  petal_length  petal_width          species  \\\n",
       "1            4.9          3.1           1.5          0.1      Iris-setosa   \n",
       "2            4.4          3.0           1.3          0.2      Iris-setosa   \n",
       "3            5.1          3.4           1.5          0.2      Iris-setosa   \n",
       "4            5.0          3.5           1.3          0.3      Iris-setosa   \n",
       "5            4.5          2.3           1.3          0.3      Iris-setosa   \n",
       "6            4.4          3.2           1.3          0.2      Iris-setosa   \n",
       "7            5.0          3.5           1.6          0.6      Iris-setosa   \n",
       "8            5.1          3.8           1.9          0.4      Iris-setosa   \n",
       "9            4.8          3.0           1.4          0.3      Iris-setosa   \n",
       "10           5.1          3.8           1.6          0.2      Iris-setosa   \n",
       "11           4.6          3.2           1.4          0.2      Iris-setosa   \n",
       "12           5.3          3.7           1.5          0.2      Iris-setosa   \n",
       "13           5.0          3.3           1.4          0.2      Iris-setosa   \n",
       "14           6.3          2.3           4.4          1.3  Iris-versicolor   \n",
       "15           5.6          3.0           4.1          1.3  Iris-versicolor   \n",
       "16           5.5          2.5           4.0          1.3  Iris-versicolor   \n",
       "17           5.5          2.6           4.4          1.2  Iris-versicolor   \n",
       "18           6.1          3.0           4.6          1.4  Iris-versicolor   \n",
       "19           5.8          2.6           4.0          1.2  Iris-versicolor   \n",
       "20           5.0          2.3           3.3          1.0  Iris-versicolor   \n",
       "21           5.6          2.7           4.2          1.3  Iris-versicolor   \n",
       "22           5.7          3.0           4.2          1.2  Iris-versicolor   \n",
       "23           5.7          2.9           4.2          1.3  Iris-versicolor   \n",
       "24           6.2          2.9           4.3          1.3  Iris-versicolor   \n",
       "25           5.1          2.5           3.0          1.1  Iris-versicolor   \n",
       "26           5.7          2.8           4.1          1.3  Iris-versicolor   \n",
       "27           6.0          3.0           4.8          1.8   Iris-virginica   \n",
       "28           6.9          3.1           5.4          2.1   Iris-virginica   \n",
       "29           6.7          3.1           5.6          2.4   Iris-virginica   \n",
       "30           6.9          3.1           5.1          2.3   Iris-virginica   \n",
       "31           5.8          2.7           5.1          1.9   Iris-virginica   \n",
       "32           6.8          3.2           5.9          2.3   Iris-virginica   \n",
       "33           6.7          3.3           5.7          2.5   Iris-virginica   \n",
       "34           6.7          3.0           5.2          2.3   Iris-virginica   \n",
       "35           6.3          2.5           5.0          1.9   Iris-virginica   \n",
       "36           6.5          3.0           5.2          2.0   Iris-virginica   \n",
       "37           6.2          3.4           5.4          2.3   Iris-virginica   \n",
       "38           5.9          3.0           5.1          1.8   Iris-virginica   \n",
       "\n",
       "         prediction  \n",
       "1       Iris-setosa  \n",
       "2       Iris-setosa  \n",
       "3       Iris-setosa  \n",
       "4       Iris-setosa  \n",
       "5       Iris-setosa  \n",
       "6       Iris-setosa  \n",
       "7       Iris-setosa  \n",
       "8       Iris-setosa  \n",
       "9       Iris-setosa  \n",
       "10      Iris-setosa  \n",
       "11      Iris-setosa  \n",
       "12      Iris-setosa  \n",
       "13      Iris-setosa  \n",
       "14  Iris-versicolor  \n",
       "15  Iris-versicolor  \n",
       "16  Iris-versicolor  \n",
       "17  Iris-versicolor  \n",
       "18  Iris-versicolor  \n",
       "19  Iris-versicolor  \n",
       "20  Iris-versicolor  \n",
       "21  Iris-versicolor  \n",
       "22  Iris-versicolor  \n",
       "23  Iris-versicolor  \n",
       "24  Iris-versicolor  \n",
       "25  Iris-versicolor  \n",
       "26  Iris-versicolor  \n",
       "27   Iris-virginica  \n",
       "28   Iris-virginica  \n",
       "29   Iris-virginica  \n",
       "30   Iris-virginica  \n",
       "31   Iris-virginica  \n",
       "32   Iris-virginica  \n",
       "33   Iris-virginica  \n",
       "34   Iris-virginica  \n",
       "35   Iris-virginica  \n",
       "36   Iris-virginica  \n",
       "37   Iris-virginica  \n",
       "38   Iris-virginica  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can print your actual y from test and predicted y using test\n",
    "# you might have to check the dimensions of each to make sure you can compare them later\n",
    "# TODO\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NmiPBk2zIApf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model had a 1.0 accuracy rate.\n"
     ]
    }
   ],
   "source": [
    "'Compute accuracy'\n",
    "# You can use sci-kit learn's accuracy score to evaluate the performance of your model on test data\n",
    "# TODO\n",
    "print(\"The model had a \" + str((accuracy_score(test_df['species'], test_df['prediction']))) + \" accuracy rate.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NdJTmp82IAph"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "colab": {
   "name": "hw3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
